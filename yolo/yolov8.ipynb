{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-31T00:38:28.640676Z","iopub.status.busy":"2024-05-31T00:38:28.640292Z","iopub.status.idle":"2024-05-31T00:38:28.646089Z","shell.execute_reply":"2024-05-31T00:38:28.645237Z","shell.execute_reply.started":"2024-05-31T00:38:28.640636Z"},"id":"_vPAseCAb4bI","outputId":"3fb3fabc-9807-4654-b5d5-8d349c203d44","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/moborobot/RoboVoyager/yolo\n"]}],"source":["import os\n","HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-31T00:38:28.648038Z","iopub.status.busy":"2024-05-31T00:38:28.647446Z","iopub.status.idle":"2024-05-31T00:38:55.468271Z","shell.execute_reply":"2024-05-31T00:38:55.467344Z","shell.execute_reply.started":"2024-05-31T00:38:28.648004Z"},"id":"S3qqoVPycI8m","outputId":"c697d39d-a89b-4679-c24d-af80fde9f7c6","trusted":true},"outputs":[],"source":["# Pip install method (recommended)\n","\n","#%pip install ultralytics==8.0.134\n","from IPython import display\n","display.clear_output()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.134 ðŸš€ Python-3.8.10 torch-2.3.0 CPU\n","Setup complete âœ… (12 CPUs, 29.9 GB RAM, 35.6/56.7 GB disk)\n"]}],"source":["\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T00:38:55.471861Z","iopub.status.busy":"2024-05-31T00:38:55.471414Z","iopub.status.idle":"2024-05-31T00:38:55.475962Z","shell.execute_reply":"2024-05-31T00:38:55.475091Z","shell.execute_reply.started":"2024-05-31T00:38:55.471834Z"},"id":"B4IvNHefcW5c","trusted":true},"outputs":[],"source":["from ultralytics import YOLO\n","\n","from IPython.display import display, Image"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-31T00:39:43.406570Z","iopub.status.busy":"2024-05-31T00:39:43.406258Z","iopub.status.idle":"2024-05-31T00:39:43.987901Z","shell.execute_reply":"2024-05-31T00:39:43.986920Z","shell.execute_reply.started":"2024-05-31T00:39:43.406539Z"},"id":"m2isD2pocVTL","outputId":"575c158b-4e0b-4332-eb29-d092fd117f08","trusted":true},"outputs":[],"source":["from ultralytics import YOLO\n","\n","# Load a model\n","#model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n","model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","image 1/1 /home/moborobot/RoboVoyager/yolo/image-2022_08_02-16_30_23_725.png: 192x320 2 persons, 3 chairs, 214.0ms\n","Speed: 2.3ms preprocess, 214.0ms inference, 9.4ms postprocess per image at shape (1, 3, 192, 320)\n"]}],"source":["results = model.predict(HOME + \"/\" +\"image-2022_08_02-16_30_23_725.png\", save=False, imgsz=320, conf=0.6)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[ultralytics.yolo.engine.results.Results object with attributes:\n","\n","boxes: ultralytics.yolo.engine.results.Boxes object\n","keypoints: None\n","keys: ['boxes']\n","masks: None\n","names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n","orig_img: array([[[59, 60, 58],\n","        [60, 62, 59],\n","        [60, 60, 58],\n","        ...,\n","        [75, 73, 72],\n","        [76, 74, 73],\n","        [77, 75, 74]],\n","\n","       [[58, 59, 57],\n","        [60, 61, 58],\n","        [59, 59, 58],\n","        ...,\n","        [74, 72, 71],\n","        [75, 73, 72],\n","        [74, 72, 71]],\n","\n","       [[56, 57, 55],\n","        [58, 59, 56],\n","        [58, 59, 57],\n","        ...,\n","        [74, 70, 70],\n","        [74, 70, 70],\n","        [73, 71, 70]],\n","\n","       ...,\n","\n","       [[47, 48, 46],\n","        [45, 46, 44],\n","        [49, 50, 48],\n","        ...,\n","        [69, 65, 64],\n","        [69, 65, 64],\n","        [69, 65, 64]],\n","\n","       [[48, 49, 47],\n","        [46, 47, 45],\n","        [47, 48, 46],\n","        ...,\n","        [69, 65, 64],\n","        [70, 66, 64],\n","        [70, 66, 65]],\n","\n","       [[46, 47, 45],\n","        [49, 50, 48],\n","        [47, 48, 46],\n","        ...,\n","        [68, 64, 63],\n","        [68, 64, 63],\n","        [68, 64, 63]]], dtype=uint8)\n","orig_shape: (1080, 1920)\n","path: '/home/moborobot/RoboVoyager/yolo/image-2022_08_02-16_30_23_725.png'\n","probs: None\n","save_dir: None\n","speed: {'preprocess': 2.3360252380371094, 'inference': 214.0498161315918, 'postprocess': 9.382247924804688}]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import cv2\n","for result in results:\n","    boxes = result.boxes.xyxy  # xyxy format: x1, y1, x2, y2\n","    img = result.orig_img\n","    # Draw the bounding boxes on the image\n","    for box in boxes:\n","        x1, y1, x2, y2 = box\n","        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n","    # Display the predicted image\n","    cv2.imshow(\"Predicted Image\", img)\n","    cv2.waitKey(0)\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'boxes'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the bounding box points\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m boxes \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[38;5;241m.\u001b[39mxyxy  \u001b[38;5;66;03m# xyxy format: x1, y1, x2, y2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get the predicted image\u001b[39;00m\n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39morig_img\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'boxes'"]}],"source":["# Get the bounding box points\n","boxes = results.boxes.xyxy  # xyxy format: x1, y1, x2, y2\n","\n","# Get the predicted image\n","img = results.orig_img\n","\n","# Draw the bounding boxes on the image\n","for box in boxes:\n","    x1, y1, x2, y2 = box\n","    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n","    #cv2.putText(img, f\"Class: {obj['class_id']} Conf: {obj['confidence']:.2f}\", (obj[\"x\"], obj[\"y\"] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5)\n","\n","# Display the predicted image\n","cv2.imshow(\"Predicted Image\", img)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"error","evalue":"OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:274: error: (-5:Bad argument) Can't read ONNX file: yolov8s.onnx in function 'cv::dnn::dnn4_v20230620::ONNXImporter::ONNXImporter'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the YOLOv8 model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNetFromONNX\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov8s.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[0;32m      8\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Asus/Desktop/480/yolo/image-2022_08_02-16_30_23_725.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:274: error: (-5:Bad argument) Can't read ONNX file: yolov8s.onnx in function 'cv::dnn::dnn4_v20230620::ONNXImporter::ONNXImporter'\n"]}],"source":["import cv2\n","import numpy as np\n","\n","# Load the YOLOv8 model\n","net = cv2.dnn.readNetFromONNX(\"yolov8s.onnx\")\n","\n","# Load the image\n","img = cv2.imread(\"C:/Users/Asus/Desktop/480/yolo/image-2022_08_02-16_30_23_725.png\")\n","\n","# Get the image height and width\n","h, w, _ = img.shape\n","\n","# Create a blob from the image\n","blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), swapRB=True, crop=False)\n","\n","# Set the input blob for the network\n","net.setInput(blob)\n","\n","# Run the forward pass\n","outputs = net.forward(net.getUnconnectedOutLayersNames())\n","\n","# Initialize the list of detected objects\n","objects = []\n","\n","# Iterate through the output layers\n","for output in outputs:\n","    # Iterate through the detections in the output layer\n","    for detection in output:\n","        # Get the scores, class_id, and confidence\n","        scores = detection[5:]\n","        class_id = np.argmax(scores)\n","        confidence = scores[class_id]\n","\n","        # Filter out weak predictions\n","        if confidence > 0.5:\n","            # Get the bounding box coordinates\n","            x, y, w, h = detection[0:4] * np.array([w, h, w, h])\n","            x, y, x_end, y_end = int(x - w/2), int(y - h/2), int(x + w/2), int(y + h/2)\n","\n","            # Create a bounding box object\n","            obj = {\n","                \"class_id\": class_id,\n","                \"confidence\": confidence,\n","                \"x\": x,\n","                \"y\": y,\n","                \"w\": w,\n","                \"h\": h\n","            }\n","\n","            # Add the object to the list\n","            objects.append(obj)\n","\n","# Draw the bounding boxes on the image\n","for obj in objects:\n","    cv2.rectangle(img, (obj[\"x\"], obj[\"y\"]), (obj[\"x\"] + obj[\"w\"], obj[\"y\"] + obj[\"h\"]), (0, 255, 0), 2)\n","    cv2.putText(img, f\"Class: {obj['class_id']} Conf: {obj['confidence']:.2f}\", (obj[\"x\"], obj[\"y\"] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5124889,"sourceId":8570950,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
